# Event Impact Model — Research Memo

## 1. Hypothesis
Regulatory filing events (SEC 8-K / 10-Q / 10-K) carry incremental information that can be mapped to a tradable timestamp and used to predict short-horizon post-event returns.

The core claim is not “alpha exists”, but that the event layer is timestamped and aligned correctly and that any signal is evaluated out-of-sample with leakage guards.

## 2. Data
**Universe**
- Snapshot from SEC company tickers (`data/raw/universe_sec_YYYY-MM-DD.csv`).

**Events**
- EDGAR submissions metadata, using `acceptanceDateTime` as the event timestamp.
- Forms: 8-K, 10-Q, 10-K (configurable).

**Prices**
- Daily OHLCV from Stooq.
- Benchmark: SPY.

### Caveats
- Universe snapshot can introduce survivorship/selection bias without historical membership.
- Coverage gaps in Stooq and EDGAR lead to event drops; this can create non-random missingness.
- Daily granularity compresses intraday microstructure; execution realism is limited by design.

## 3. Event timestamping and alignment
- `acceptanceDateTime` is parsed as UTC and converted to US/Eastern.
- Session bucket: premarket / intraday / afterhours.
- Mapping to an effective NYSE trading date is calendar-aware (weekends/holidays).

Conservative daily tradability mapping:
- premarket  → same trading day
- intraday   → next trading day
- afterhours → next trading day

This avoids “same-day close” artifacts when the information arrives after the close.

## 4. Event study
**Returns**
- Close-to-close daily returns.

**Abnormal returns**
- Market model vs SPY, estimated per ticker:
  - Estimation window: [-120, -21] trading days relative to event
  - Event window: [-10, +5]
- AR = actual − predicted
- CAR/CAAR derived by aggregation.

**Bias guards**
- Estimation and event windows are separated.
- Pre-trend check (CAR on negative taus) to detect drift before the event.
- Subgroup testing uses Benjamini–Hochberg FDR control.

## 5. Predictive modeling
**Target**
- CAR[+1, +5] from abnormal returns (post-event drift proxy).

**Features**
- Pre-event only: momentum, volatility, liquidity proxy, calendar features, event metadata.

**Models**
- Baselines: Ridge regression; logistic baseline on sign(target).
- Nonlinear: LightGBM regression.

**Cross-validation**
- Walk-forward splitter with purge/embargo-style guardrails around the label horizon.

## 6. Backtesting
Two complementary views:

**Event-level portfolios**
- Cross-sectional long top-q / short bottom-q based on out-of-sample predictions.
- Cost proxy: turnover-based bps.

**Daily holdings engine**
- Entry/exit based on delay and fixed holding horizon.
- Constraints: max positions, per-name cap, gross exposure target.
- Optional portfolio-level vol targeting (rolling lookback).

All reported performance is based on out-of-sample predictions and includes explicit costs.

## 7. Results
Results are generated by the pipeline and stored in:
- `reports/REPORT.md` (autogenerated)
- `reports/figures/*`
- `data/processed/cv_metrics*.csv`
- `reports/backtest_engine_summary*.csv`
- `reports/robustness_*.csv`

## 8. Robustness and sanity checks
- Random prediction baselines.
- Subsample stability (by year and event buckets).
- Within-day prediction shuffle to verify that ranking drives results rather than day-level structure.

These checks are used to detect accidental backtest structure; they are not used for parameter selection.

## 9. Failure modes / risks
- Timestamp mapping errors (afterhours mapped to the wrong trading date) can create false alpha.
- Feature availability timing must remain strictly pre-event (revision/leakage risk).
- Universe/coverage bias from snapshot + missing price data.
- Small-sample instability for sparse event types.

## 10. Next steps
- Improve universe construction (historical membership if available).
- Add richer features with strict as-of handling (sector, size, ADV, dispersion proxies).
- Improve execution realism (open prices, slippage proxies, capacity constraints).
- Package polish (README/Makefile and a clean one-command run).
